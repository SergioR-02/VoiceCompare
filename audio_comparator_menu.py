#!/usr/bin/env python3
"""
Men√∫ integrado para comparar audios con diferentes modelos 3D-Speaker
"""

import os
import sys
import torch
import torchaudio
import numpy as np
from pathlib import Path
import subprocess
import re
import sounddevice as sd
import wave
import time
import threading

# Agregar rutas del proyecto
sys.path.append(os.path.join(os.path.dirname(__file__), 'speakerlab'))

from speakerlab.process.processor import FBank
from speakerlab.utils.builder import dynamic_import

class AudioComparator:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.feature_extractor = FBank(80, sample_rate=16000, mean_nor=True)
        
        # Configuraciones de modelos disponibles
        self.models_config = {
            "1": {
                "name": "CAM++ (Recomendado)",
                "description": "M√°s r√°pido y preciso para chino",
                "model_id": "iic/speech_campplus_sv_zh-cn_16k-common",
                "config": {
                    'obj': 'speakerlab.models.campplus.DTDNN.CAMPPlus',
                    'args': {
                        'feat_dim': 80,
                        'embedding_size': 192,
                    },
                },
                "model_paths": [
                    "pretrained/speech_campplus_sv_zh-cn_16k-common/campplus_cn_common.bin",
                    "pretrained/speech_campplus_sv_zh-cn_16k-common/pytorch_model.bin",
                ],
                "thresholds": [0.75, 0.65, 0.50, 0.35]
            },
            "2": {
                "name": "ERes2Net Base",
                "description": "Modelo robusto y confiable",
                "model_id": "iic/speech_eres2net_base_sv_zh-cn_3dspeaker_16k",
                "config": {
                    'obj': 'speakerlab.models.eres2net.ERes2Net.ERes2Net',
                    'args': {
                        'feat_dim': 80,
                        'embedding_size': 512,
                        'm_channels': 32,
                    },
                },
                "model_paths": [
                    "pretrained/speech_eres2net_base_sv_zh-cn_3dspeaker_16k/eres2net_base_model.ckpt",
                ],
                "thresholds": [0.70, 0.60, 0.45, 0.30]
            },
            "3": {
                "name": "Script Original (infer_sv.py)",
                "description": "Usar el script original del proyecto",
                "use_original": True
            }
        }

    def print_header(self):
        """Imprimir header del men√∫"""
        print("\n" + "="*60)
        print("üé§ COMPARADOR DE AUDIOS 3D-SPEAKER üé§")
        print("="*60)
        print(f"üíª Dispositivo: {self.device}")
        total_audios = len(self.get_audio_files())
        print(f"üéµ Archivos de audio encontrados: {total_audios}")
        print("="*60)

    def get_audio_files(self):
        """Obtener todos los archivos de audio disponibles en la carpeta data"""
        audio_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.ogg']
        audio_files = []
        
        # Buscar solo en el directorio data
        data_dir = 'data'
        
        if os.path.exists(data_dir):
            for root, dirs, files in os.walk(data_dir):
                for file in files:
                    if any(file.lower().endswith(ext) for ext in audio_extensions):
                        full_path = os.path.join(root, file)
                        # Filtrar archivos muy peque√±os o temporales
                        if os.path.getsize(full_path) > 1000:  # Al menos 1KB
                            audio_files.append(full_path)
        
        return sorted(audio_files)

    def select_model(self):
        """Seleccionar modelo a usar"""
        print("\nüìä SELECCIONA EL MODELO:")
        print("-" * 40)
        
        for key, model in self.models_config.items():
            print(f"{key}. {model['name']}")
            print(f"   {model['description']}")
            if 'model_paths' in model:
                # Verificar si el modelo est√° disponible
                model_available = any(os.path.exists(path) for path in model['model_paths'])
                status = "‚úÖ Disponible" if model_available else "‚ùå No encontrado"
                print(f"   {status}")
            
        print("\n4. üîÑ Comparar TODOS los audios (matriz de similitud)")
        print("5. üé§ Grabaci√≥n EN VIVO (comparar con archivos conocidos)")
        print("0. Salir")
        
        while True:
            try:
                choice = input("\nSelecciona una opci√≥n (0-5): ").strip()
                
                if choice == "0":
                    print("üëã ¬°Hasta luego!")
                    sys.exit(0)
                elif choice == "4":
                    return "compare_all"
                elif choice == "5":
                    return "live_recording"
                elif choice in self.models_config:
                    return choice
                else:
                    print("‚ùå Opci√≥n inv√°lida. Intenta de nuevo.")
            except KeyboardInterrupt:
                print("\nüëã ¬°Hasta luego!")
                sys.exit(0)

    def get_audio_info(self, audio_file):
        """Obtener informaci√≥n detallada del archivo de audio"""
        try:
            wav, fs = torchaudio.load(audio_file)
            duration = wav.shape[-1] / fs
            channels = wav.shape[0] if len(wav.shape) > 1 else 1
            file_size = os.path.getsize(audio_file) / 1024  # KB
            
            return {
                'duration': duration,
                'sample_rate': fs,
                'channels': channels,
                'file_size': file_size,
                'samples': wav.shape[-1]
            }
        except Exception as e:
            return None

    def select_audio_file(self, prompt_text):
        """Seleccionar archivo de audio"""
        audio_files = self.get_audio_files()
        
        if not audio_files:
            print("‚ùå No se encontraron archivos de audio")
            return None
        
        print(f"\n{prompt_text}")
        print("-" * 50)
        
        # Agrupar por directorio para mejor visualizaci√≥n
        files_by_dir = {}
        for file in audio_files:
            dir_name = os.path.dirname(file)
            if dir_name not in files_by_dir:
                files_by_dir[dir_name] = []
            files_by_dir[dir_name].append(file)
        
        file_index = 1
        index_to_file = {}
        
        for dir_name, files in files_by_dir.items():
            print(f"\nüìÅ {dir_name}:")
            for file in files:
                filename = os.path.basename(file)
                
                # Obtener informaci√≥n del audio
                audio_info = self.get_audio_info(file)
                if audio_info:
                    info_str = f"({audio_info['duration']:.1f}s, {audio_info['sample_rate']}Hz, {audio_info['file_size']:.1f}KB)"
                else:
                    info_str = f"({os.path.getsize(file) / 1024:.1f} KB)"
                
                print(f"  {file_index:2d}. {filename} {info_str}")
                index_to_file[file_index] = file
                file_index += 1
        
        print("\n  0. Volver al men√∫ principal")
        print("  i. Mostrar informaci√≥n detallada de un archivo")
        
        while True:
            try:
                choice = input(f"\nSelecciona un archivo (1-{len(audio_files)}, i para info): ")
                
                if choice == "0":
                    return None
                elif choice.lower() == "i":
                    info_choice = input("N√∫mero del archivo para ver informaci√≥n: ")
                    try:
                        info_index = int(info_choice)
                        if info_index in index_to_file:
                            self.show_audio_info(index_to_file[info_index])
                        else:
                            print(f"‚ùå N√∫mero inv√°lido")
                    except ValueError:
                        print("‚ùå Por favor, ingresa un n√∫mero v√°lido")
                    continue
                
                index = int(choice)
                if index in index_to_file:
                    return index_to_file[index]
                else:
                    print(f"‚ùå Por favor, ingresa un n√∫mero entre 1 y {len(audio_files)}")
            except ValueError:
                print("‚ùå Por favor, ingresa un n√∫mero v√°lido")
            except KeyboardInterrupt:
                print("\nüëã Regresando al men√∫ principal...")
                return None

    def show_audio_info(self, audio_file):
        """Mostrar informaci√≥n detallada del archivo de audio"""
        print(f"\nüìÑ INFORMACI√ìN DEL ARCHIVO:")
        print("=" * 50)
        print(f"üìÅ Archivo: {os.path.basename(audio_file)}")
        print(f"üìÇ Ruta: {audio_file}")
        
        audio_info = self.get_audio_info(audio_file)
        if audio_info:
            print(f"‚è±Ô∏è  Duraci√≥n: {audio_info['duration']:.2f} segundos")
            print(f"üîä Frecuencia: {audio_info['sample_rate']} Hz")
            print(f"üìª Canales: {audio_info['channels']}")
            print(f"üìä Muestras: {audio_info['samples']:,}")
            print(f"üíæ Tama√±o: {audio_info['file_size']:.1f} KB")
            
            # Verificar si es adecuado para el modelo
            if audio_info['sample_rate'] != 16000:
                print(f"‚ö†Ô∏è  Nota: El archivo ser√° resampleado de {audio_info['sample_rate']}Hz a 16000Hz")
            
            if audio_info['duration'] < 1.0:
                print(f"‚ö†Ô∏è  Advertencia: Archivo muy corto ({audio_info['duration']:.2f}s). Puede afectar la precisi√≥n.")
            elif audio_info['duration'] > 30.0:
                print(f"‚ÑπÔ∏è  Informaci√≥n: Archivo largo ({audio_info['duration']:.2f}s). Solo se usar√° una porci√≥n.")
        else:
            print("‚ùå No se pudo leer la informaci√≥n del archivo")
        
        print("=" * 50)
        input("Presiona Enter para continuar...")

    def load_audio(self, wav_file, target_fs=16000):
        """Cargar y procesar archivo de audio"""
        wav, fs = torchaudio.load(wav_file)
        
        if fs != target_fs:
            print(f'[INFO]: Resampling {os.path.basename(wav_file)} from {fs} to {target_fs} Hz')
            wav = torchaudio.functional.resample(wav, fs, target_fs)
        
        if wav.shape[0] > 1:
            wav = wav[0, :].unsqueeze(0)
        
        return wav

    def extract_embedding(self, wav_file, model):
        """Extraer embedding de un archivo de audio"""
        wav = self.load_audio(wav_file)
        feat = self.feature_extractor(wav).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            embedding = model(feat).detach().squeeze(0).cpu().numpy()
        
        return embedding

    def cosine_similarity(self, emb1, emb2):
        """Calcular similitud coseno entre dos embeddings"""
        emb1_norm = emb1 / np.linalg.norm(emb1)
        emb2_norm = emb2 / np.linalg.norm(emb2)
        similarity = np.dot(emb1_norm, emb2_norm)
        return similarity

    def compare_with_original_script(self, model_choice, audio1, audio2):
        """Usar el script original infer_sv.py"""
        model_config = self.models_config[model_choice]
        script_path = Path("speakerlab") / "bin" / "infer_sv.py"
        
        cmd = [
            sys.executable,
            str(script_path),
            "--model_id", model_config["model_id"],
            "--wavs", audio1, audio2
        ]
        
        print(f"üîÑ Ejecutando script original...")
        print(f"üìä Modelo: {model_config['name']}")
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path(__file__).parent)
            
            # Buscar el score en la salida
            lines = result.stdout.split('\n')
            score = None
            
            for line in lines:
                if "The similarity score" in line:
                    match = re.search(r'(\d+\.\d+)', line)
                    if match:
                        score = float(match.group(1))
                        break
            
            if score is not None:
                print(f"\nüìä RESULTADOS:")
                print(f"üéØ Similitud coseno: {score:.4f}")
                
                # Interpretaci√≥n usando thresholds del modelo
                thresholds = model_config.get("thresholds", [0.70, 0.60, 0.45, 0.30])
                self.interpret_results(score, thresholds, True)
                
                return score
            else:
                print("‚ùå No se pudo extraer el score de similitud")
                if result.stderr:
                    print(f"Error: {result.stderr}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error ejecutando script original: {e}")
            return None

    def compare_with_model(self, model_choice, audio1, audio2):
        """Comparar usando modelo cargado directamente"""
        model_config = self.models_config[model_choice]
        
        print(f"ü§ñ Cargando modelo {model_config['name']}...")
        
        try:
            # Crear modelo
            model_class = dynamic_import(model_config['config']['obj'])
            model = model_class(**model_config['config']['args'])
            
            # Intentar cargar pesos preentrenados
            use_pretrained = False
            for model_path in model_config['model_paths']:
                if os.path.exists(model_path):
                    try:
                        print(f"üì¶ Cargando pesos desde {os.path.basename(model_path)}...")
                        checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
                        
                        if isinstance(checkpoint, dict):
                            if 'model' in checkpoint:
                                model.load_state_dict(checkpoint['model'], strict=False)
                            elif 'state_dict' in checkpoint:
                                model.load_state_dict(checkpoint['state_dict'], strict=False)
                            else:
                                model.load_state_dict(checkpoint, strict=False)
                        else:
                            model.load_state_dict(checkpoint, strict=False)
                        
                        use_pretrained = True
                        print("‚úÖ Modelo preentrenado cargado exitosamente")
                        break
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Error cargando {model_path}: {e}")
                        continue
            
            if not use_pretrained:
                print("‚ö†Ô∏è  Usando modelo sin entrenar (resultados no confiables)")
            
            model.to(self.device)
            model.eval()
            
            # Extraer embeddings
            print("üîÑ Procesando audios...")
            embedding1 = self.extract_embedding(audio1, model)
            embedding2 = self.extract_embedding(audio2, model)
            
            # Calcular similitud
            similarity = self.cosine_similarity(embedding1, embedding2)
            
            print(f"\nüìä RESULTADOS:")
            print(f"üéØ Similitud coseno: {similarity:.4f}")
            print(f"üìä Embedding: {embedding1.shape[0]} dimensiones")
            
            # Interpretaci√≥n
            thresholds = model_config.get("thresholds", [0.70, 0.60, 0.45, 0.30])
            self.interpret_results(similarity, thresholds, use_pretrained)
            
            return similarity
            
        except Exception as e:
            print(f"‚ùå Error con modelo {model_config['name']}: {e}")
            return None

    def interpret_results(self, similarity, thresholds, use_pretrained):
        """Interpretar resultados seg√∫n thresholds"""
        if use_pretrained:
            if similarity > thresholds[0]:
                status = "üü¢ MISMO LOCUTOR"
                confidence = "MUY ALTA CONFIANZA"
            elif similarity > thresholds[1]:
                status = "üü¢ PROBABLEMENTE MISMO LOCUTOR"
                confidence = "ALTA CONFIANZA"
            elif similarity > thresholds[2]:
                status = "üü° POSIBLEMENTE MISMO LOCUTOR"  
                confidence = "MEDIA CONFIANZA"
            elif similarity > thresholds[3]:
                status = "üü† PROBABLEMENTE DIFERENTES"
                confidence = "BAJA SIMILITUD"
            else:
                status = "üî¥ LOCUTORES DIFERENTES"
                confidence = "MUY BAJA SIMILITUD"
        else:
            status = "‚ö†Ô∏è  RESULTADO NO CONFIABLE"
            confidence = "MODELO SIN ENTRENAR"
        
        print(f"üéØ Resultado: {status}")
        print(f"üìà Confianza: {confidence}")

    def compare_all_audios(self, model_choice):
        """Comparar todos los audios disponibles y crear matriz de similitud"""
        audio_files = self.get_audio_files()
        
        if len(audio_files) < 2:
            print("‚ùå Se necesitan al menos 2 archivos de audio")
            return
        
        if len(audio_files) > 10:
            print(f"‚ö†Ô∏è  Se encontraron {len(audio_files)} archivos. Esto puede tomar mucho tiempo.")
            confirm = input("¬øContinuar? (s/n): ").lower()
            if confirm not in ['s', 'si', 's√≠', 'y', 'yes']:
                return
        
        model_config = self.models_config[model_choice]
        print(f"\nüîÑ Comparando {len(audio_files)} archivos con {model_config['name']}...")
        
        # Cargar modelo
        try:
            model_class = dynamic_import(model_config['config']['obj'])
            model = model_class(**model_config['config']['args'])
            
            # Cargar pesos preentrenados
            use_pretrained = False
            for model_path in model_config['model_paths']:
                if os.path.exists(model_path):
                    try:
                        checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
                        if isinstance(checkpoint, dict):
                            if 'model' in checkpoint:
                                model.load_state_dict(checkpoint['model'], strict=False)
                            elif 'state_dict' in checkpoint:
                                model.load_state_dict(checkpoint['state_dict'], strict=False)
                            else:
                                model.load_state_dict(checkpoint, strict=False)
                        else:
                            model.load_state_dict(checkpoint, strict=False)
                        use_pretrained = True
                        break
                    except Exception as e:
                        continue
            
            model.to(self.device)
            model.eval()
            
            # Extraer embeddings de todos los archivos
            print("üîÑ Extrayendo embeddings...")
            embeddings = {}
            file_names = []
            
            for i, audio_file in enumerate(audio_files):
                try:
                    print(f"   üìÑ Procesando {i+1}/{len(audio_files)}: {os.path.basename(audio_file)}")
                    embedding = self.extract_embedding(audio_file, model)
                    embeddings[audio_file] = embedding
                    file_names.append(os.path.basename(audio_file))
                except Exception as e:
                    print(f"   ‚ùå Error con {audio_file}: {e}")
                    continue
            
            if len(embeddings) < 2:
                print("‚ùå No se pudieron procesar suficientes archivos")
                return
            
            # Crear matriz de similitud
            print("\nüìä Calculando matriz de similitud...")
            similarity_matrix = np.zeros((len(embeddings), len(embeddings)))
            audio_list = list(embeddings.keys())
            
            for i, audio1 in enumerate(audio_list):
                for j, audio2 in enumerate(audio_list):
                    if i == j:
                        similarity_matrix[i, j] = 1.0
                    elif i < j:  # Solo calcular la mitad superior
                        similarity = self.cosine_similarity(embeddings[audio1], embeddings[audio2])
                        similarity_matrix[i, j] = similarity
                        similarity_matrix[j, i] = similarity  # Simetr√≠a
            
            # Mostrar resultados
            print("\n" + "="*80)
            print("üìä MATRIZ DE SIMILITUD")
            print("="*80)
            
            # Header con nombres de archivos
            header = "Archivo".ljust(20)
            for name in file_names:
                header += f"{name[:10]:<12}"
            print(header)
            print("-" * len(header))
            
            # Filas de la matriz
            for i, name in enumerate(file_names):
                row = f"{name[:18]:<20}"
                for j in range(len(file_names)):
                    score = similarity_matrix[i, j]
                    if i == j:
                        row += f"{'1.0000':<12}"
                    else:
                        row += f"{score:.4f}{'':6}"
                print(row)
            
            # An√°lisis de grupos
            print("\nüìà AN√ÅLISIS DE GRUPOS:")
            print("-" * 40)
            
            threshold = model_config.get("thresholds", [0.70, 0.60, 0.45, 0.30])[1]  # Usar segundo threshold
            high_similarity_pairs = []
            
            for i in range(len(audio_list)):
                for j in range(i+1, len(audio_list)):
                    if similarity_matrix[i, j] > threshold:
                        pair = (file_names[i], file_names[j], similarity_matrix[i, j])
                        high_similarity_pairs.append(pair)
            
            if high_similarity_pairs:
                print(f"üü¢ Pares con alta similitud (> {threshold:.2f}):")
                for name1, name2, score in sorted(high_similarity_pairs, key=lambda x: x[2], reverse=True):
                    print(f"   {name1} ‚Üî {name2}: {score:.4f}")
            else:
                print(f"üî¥ No se encontraron pares con alta similitud (> {threshold:.2f})")
            
            # Guardar resultados
            save_results = input("\nüíæ ¬øGuardar resultados en archivo? (s/n): ").lower()
            if save_results in ['s', 'si', 's√≠', 'y', 'yes']:
                import csv
                import datetime
                
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"similarity_matrix_{model_choice}_{timestamp}.csv"
                
                with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
                    writer = csv.writer(csvfile)
                    
                    # Header
                    header_row = ['Archivo'] + file_names
                    writer.writerow(header_row)
                    
                    # Datos
                    for i, name in enumerate(file_names):
                        row = [name] + [f"{similarity_matrix[i, j]:.4f}" for j in range(len(file_names))]
                        writer.writerow(row)
                
                print(f"‚úÖ Resultados guardados en: {filename}")
            
        except Exception as e:
            print(f"‚ùå Error en comparaci√≥n masiva: {e}")
            import traceback
            traceback.print_exc()

    def record_audio(self, duration=5, sample_rate=16000, auto_start=False):
        """Grabar audio desde el micr√≥fono
        
        Args:
            duration (int): Duraci√≥n en segundos
            sample_rate (int): Frecuencia de muestreo
            auto_start (bool): Si True, inicia autom√°ticamente sin esperar Enter
        """
        print(f"\nüé§ GRABACI√ìN EN VIVO")
        print("=" * 50)
        print(f"‚è±Ô∏è  Duraci√≥n: {duration} segundos")
        print(f"üîä Frecuencia: {sample_rate} Hz")
        print("üì± Aseg√∫rate de tener el micr√≥fono conectado y funcionando")
        print("=" * 50)
        
        # Verificar dispositivos de audio disponibles
        try:
            devices = sd.query_devices()
            input_devices = [d for d in devices if d['max_input_channels'] > 0]
            
            if not input_devices:
                print("‚ùå No se encontraron dispositivos de entrada de audio")
                return None
            
            print(f"üéôÔ∏è  Dispositivo de entrada: {sd.default.device[0] if sd.default.device[0] is not None else 'Default'}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Advertencia: No se pudo verificar dispositivos de audio: {e}")
        
        # Solo solicitar Enter si no es auto_start
        if not auto_start:
            input("\nüé§ Presiona Enter cuando est√©s listo para grabar...")
        else:
            print("\nüé§ Iniciando grabaci√≥n autom√°ticamente...")
            # Peque√±a pausa para que el usuario se prepare
            time.sleep(1)
        
        print(f"\nüî¥ ¬°GRABANDO! Habla ahora por {duration} segundos...")
        
        # Contador visual
        def countdown():
            for i in range(duration, 0, -1):
                print(f"\r‚è±Ô∏è  Tiempo restante: {i} segundos", end="", flush=True)
                time.sleep(1)
            print(f"\r‚úÖ Grabaci√≥n completada!{' ' * 20}")
        
        try:
            # Iniciar contador en hilo separado
            countdown_thread = threading.Thread(target=countdown)
            countdown_thread.start()
            
            # Grabar audio
            recording = sd.rec(int(duration * sample_rate), 
                             samplerate=sample_rate, 
                             channels=1, 
                             dtype=np.float32)
            sd.wait()  # Esperar a que termine la grabaci√≥n
            
            countdown_thread.join()
            
            # Verificar que la grabaci√≥n no est√© vac√≠a
            if np.max(np.abs(recording)) < 0.001:
                print("‚ö†Ô∏è  Advertencia: La grabaci√≥n parece estar muy silenciosa")
                print("   Verifica que el micr√≥fono est√© funcionando correctamente")
            
            # Guardar temporalmente
            temp_filename = "temp_recording.wav"
            
            # Convertir a tensor de PyTorch para compatibilidad
            recording_tensor = torch.from_numpy(recording.T)  # Transponer para tener shape [channels, samples]
            torchaudio.save(temp_filename, recording_tensor, sample_rate)
            
            print(f"üíæ Audio grabado y guardado temporalmente en: {temp_filename}")
            
            return temp_filename
            
        except Exception as e:
            print(f"‚ùå Error durante la grabaci√≥n: {e}")
            return None

    def identify_speaker_live(self):
        """Funci√≥n principal para identificaci√≥n de locutor en vivo"""
        print("\nüé§ IDENTIFICACI√ìN DE LOCUTOR EN VIVO")
        print("=" * 60)
        
        # Referencias conocidas (puedes modificar estos archivos seg√∫n tus necesidades)
        reference_files = {
            "Daniel": [
                "data/daniel_2/record_out (11).wav",
                "data/daniel_2/audio_01.wav",
                "data/daniel_2/record_out.wav"
            ],
            "Hablante_1": [
                "data/hablante_1/hablante_1_02.wav",
                "data/hablante_1/hablante_1_01.wav", 
                "data/hablante_1/hablante_1_03.wav"
            ]
        }
        
        # Verificar qu√© archivos de referencia existen
        available_references = {}
        for person, files in reference_files.items():
            available_files = [f for f in files if os.path.exists(f)]
            if available_files:
                available_references[person] = available_files
        
        if not available_references:
            print("‚ùå No se encontraron archivos de referencia")
            print("   Aseg√∫rate de tener archivos en las carpetas:")
            for person, files in reference_files.items():
                print(f"   üìÅ {person}: {files[0][:20]}...")
            return
        
        print("üë• PERSONAS CONOCIDAS EN EL SISTEMA:")
        print("-" * 40)
        for person, files in available_references.items():
            print(f"üë§ {person}: {len(files)} archivos de referencia")
        
        # Configurar grabaci√≥n
        print(f"\n‚öôÔ∏è  CONFIGURACI√ìN DE GRABACI√ìN:")
        print("-" * 40)
        
        # Duraci√≥n de grabaci√≥n
        try:
            duration_input = input("‚è±Ô∏è  Duraci√≥n de grabaci√≥n en segundos (por defecto 5): ").strip()
            duration = int(duration_input) if duration_input else 5
            duration = max(2, min(duration, 30))  # Entre 2 y 30 segundos
        except ValueError:
            duration = 5
        
        # Seleccionar modelo
        print(f"\nüìä SELECCIONA EL MODELO PARA IDENTIFICACI√ìN:")
        print("-" * 40)
        
        # Solo mostrar modelos que usen el script original para mayor confiabilidad
        available_models = {}
        for key, model in self.models_config.items():
            if model.get('use_original'):
                available_models[key] = model
                print(f"{key}. {model['name']} (Script Original)")
            elif 'model_paths' in model:
                model_available = any(os.path.exists(path) for path in model['model_paths'])
                if model_available:
                    available_models[key] = model
                    print(f"{key}. {model['name']} ‚úÖ")
        
        if not available_models:
            print("‚ùå No hay modelos disponibles")
            return
        
        model_choice = input(f"\nSelecciona modelo: ").strip()
        if model_choice not in available_models:
            print("‚ùå Selecci√≥n inv√°lida")
            return
        
        # Grabar audio
        recorded_file = self.record_audio(duration)
        if not recorded_file:
            return
        
        print(f"\nüîç COMPARANDO CON PERSONAS CONOCIDAS...")
        print("=" * 60)
        
        # Comparar con cada persona
        results = {}
        
        for person, reference_files in available_references.items():
            print(f"\nüë§ Comparando con {person}...")
            person_scores = []
            
            for ref_file in reference_files[:3]:  # Usar m√°ximo 3 archivos por persona
                try:
                    print(f"   üìÑ Comparando con {os.path.basename(ref_file)}...")
                    
                    if self.models_config[model_choice].get('use_original'):
                        score = self.compare_with_original_script(model_choice, recorded_file, ref_file)
                    else:
                        score = self.compare_with_model(model_choice, recorded_file, ref_file)
                    
                    if score is not None:
                        person_scores.append(score)
                        print(f"     üéØ Similitud: {score:.4f}")
                    
                except Exception as e:
                    print(f"     ‚ùå Error: {e}")
                    continue
            
            if person_scores:
                avg_score = sum(person_scores) / len(person_scores)
                max_score = max(person_scores)
                results[person] = {
                    'avg_score': avg_score,
                    'max_score': max_score,
                    'scores': person_scores
                }
                print(f"   üìä Promedio: {avg_score:.4f}, M√°ximo: {max_score:.4f}")
        
        # Mostrar resultados finales
        print(f"\nüèÜ RESULTADOS DE IDENTIFICACI√ìN:")
        print("=" * 60)
        
        if not results:
            print("‚ùå No se pudieron realizar comparaciones")
            return
        
        # Ordenar por score promedio
        sorted_results = sorted(results.items(), key=lambda x: x[1]['avg_score'], reverse=True)
        
        best_match = sorted_results[0]
        best_person = best_match[0]
        best_avg_score = best_match[1]['avg_score']
        best_max_score = best_match[1]['max_score']
        
        print(f"ü•á MEJOR COINCIDENCIA: {best_person}")
        print(f"   üìä Score promedio: {best_avg_score:.4f}")
        print(f"   üéØ Score m√°ximo: {best_max_score:.4f}")
        
        # Interpretar resultado
        model_config = self.models_config[model_choice]
        thresholds = model_config.get("thresholds", [0.70, 0.60, 0.45, 0.30])
        
        if best_avg_score > thresholds[0]:
            confidence = "üü¢ MUY ALTA CONFIANZA - Es muy probable que sea esta persona"
        elif best_avg_score > thresholds[1]:
            confidence = "üü¢ ALTA CONFIANZA - Probablemente es esta persona"
        elif best_avg_score > thresholds[2]:
            confidence = "üü° CONFIANZA MEDIA - Podr√≠a ser esta persona"
        elif best_avg_score > thresholds[3]:
            confidence = "üü† BAJA CONFIANZA - Similitud d√©bil"
        else:
            confidence = "üî¥ MUY BAJA CONFIANZA - Probablemente es una persona desconocida"
        
        print(f"   {confidence}")
        
        # Mostrar tabla completa de resultados
        print(f"\nüìã TABLA COMPLETA DE SIMILITUDES:")
        print("-" * 60)
        for person, data in sorted_results:
            print(f"üë§ {person}:")
            print(f"   üìä Promedio: {data['avg_score']:.4f}")
            print(f"   üéØ M√°ximo: {data['max_score']:.4f}")
            print(f"   üìà Scores individuales: {[f'{s:.3f}' for s in data['scores']]}")
        
        # Limpiar archivo temporal
        try:
            os.remove(recorded_file)
            print(f"\nüóëÔ∏è  Archivo temporal eliminado")
        except:
            pass
        
        print(f"\n‚úÖ Identificaci√≥n completada")
        input("Presiona Enter para continuar...")

    def run(self):
        """Ejecutar el men√∫ principal"""
        while True:
            self.print_header()
            
            # Seleccionar modelo o acci√≥n
            choice = self.select_model()
            
            if choice == "compare_all":
                # Seleccionar modelo para comparaci√≥n masiva
                print("\nüìä SELECCIONA EL MODELO PARA COMPARACI√ìN MASIVA:")
                print("-" * 50)
                
                available_models = {}
                for key, model in self.models_config.items():
                    if not model.get('use_original'):  # Excluir script original para comparaci√≥n masiva
                        model_available = any(os.path.exists(path) for path in model['model_paths'])
                        if model_available:
                            available_models[key] = model
                            print(f"{key}. {model['name']} ‚úÖ")
                        else:
                            print(f"{key}. {model['name']} ‚ùå (No disponible)")
                
                if not available_models:
                    print("‚ùå No hay modelos disponibles para comparaci√≥n masiva")
                    input("Presiona Enter para continuar...")
                    continue
                
                model_choice = input(f"\nSelecciona modelo (1-{len(self.models_config)-1}): ").strip()
                
                if model_choice in available_models:
                    self.compare_all_audios(model_choice)
                else:
                    print("‚ùå Selecci√≥n inv√°lida")
                
                input("\nPresiona Enter para continuar...")
                continue
            
            elif choice == "live_recording":
                # Identificaci√≥n en vivo
                self.identify_speaker_live()
                continue
            
            # Flujo normal para comparaci√≥n de dos audios
            model_choice = choice
            
            # Seleccionar primer audio
            audio1 = self.select_audio_file("üéµ SELECCIONA EL PRIMER ARCHIVO DE AUDIO:")
            if not audio1:
                continue
            
            # Seleccionar segundo audio
            audio2 = self.select_audio_file("üéµ SELECCIONA EL SEGUNDO ARCHIVO DE AUDIO:")
            if not audio2:
                continue
            
            # Mostrar selecci√≥n
            print("\n" + "="*60)
            print("üìã CONFIGURACI√ìN SELECCIONADA:")
            print("="*60)
            print(f"ü§ñ Modelo: {self.models_config[model_choice]['name']}")
            print(f"üéµ Audio 1: {os.path.basename(audio1)}")
            print(f"üéµ Audio 2: {os.path.basename(audio2)}")
            print(f"üñ•Ô∏è  Dispositivo: {self.device}")
            print("="*60)
            
            # Confirmar ejecuci√≥n
            confirm = input("\n¬øContinuar con la comparaci√≥n? (s/n): ").lower()
            if confirm not in ['s', 'si', 's√≠', 'y', 'yes']:
                continue
            
            # Ejecutar comparaci√≥n
            if self.models_config[model_choice].get('use_original'):
                score = self.compare_with_original_script(model_choice, audio1, audio2)
            else:
                score = self.compare_with_model(model_choice, audio1, audio2)
            
            if score is not None:
                print(f"\n‚úÖ Comparaci√≥n completada exitosamente")
            else:
                print(f"\n‚ùå Error en la comparaci√≥n")
            
            # Preguntar si quiere hacer otra comparaci√≥n
            print("\n" + "-"*60)
            another = input("¬øRealizar otra comparaci√≥n? (s/n): ").lower()
            if another not in ['s', 'si', 's√≠', 'y', 'yes']:
                print("üëã ¬°Hasta luego!")
                break

def main():
    try:
        comparator = AudioComparator()
        comparator.run()
    except KeyboardInterrupt:
        print("\n\nüëã ¬°Hasta luego!")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
