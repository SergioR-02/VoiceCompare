#!/usr/bin/env python3
"""
Men√∫ integrado para comparar audios con diferentes modelos 3D-Speaker
"""

import os
import sys
import torch
import torchaudio
import numpy as np
from pathlib import Path
import subprocess
import re

# Agregar rutas del proyecto
sys.path.append(os.path.join(os.path.dirname(__file__), 'speakerlab'))

from speakerlab.process.processor import FBank
from speakerlab.utils.builder import dynamic_import

class AudioComparator:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.feature_extractor = FBank(80, sample_rate=16000, mean_nor=True)
        
        # Configuraciones de modelos disponibles
        self.models_config = {
            "1": {
                "name": "CAM++ (Recomendado)",
                "description": "M√°s r√°pido y preciso para chino",
                "model_id": "iic/speech_campplus_sv_zh-cn_16k-common",
                "config": {
                    'obj': 'speakerlab.models.campplus.DTDNN.CAMPPlus',
                    'args': {
                        'feat_dim': 80,
                        'embedding_size': 192,
                    },
                },
                "model_paths": [
                    "pretrained/speech_campplus_sv_zh-cn_16k-common/campplus_cn_common.bin",
                    "pretrained/speech_campplus_sv_zh-cn_16k-common/pytorch_model.bin",
                ],
                "thresholds": [0.75, 0.65, 0.50, 0.35]
            },
            "2": {
                "name": "ERes2Net Base",
                "description": "Modelo robusto y confiable",
                "model_id": "iic/speech_eres2net_base_sv_zh-cn_3dspeaker_16k",
                "config": {
                    'obj': 'speakerlab.models.eres2net.ERes2Net.ERes2Net',
                    'args': {
                        'feat_dim': 80,
                        'embedding_size': 512,
                        'm_channels': 32,
                    },
                },
                "model_paths": [
                    "pretrained/speech_eres2net_base_sv_zh-cn_3dspeaker_16k/eres2net_base_model.ckpt",
                ],
                "thresholds": [0.70, 0.60, 0.45, 0.30]
            },
            "3": {
                "name": "Script Original (infer_sv.py)",
                "description": "Usar el script original del proyecto",
                "use_original": True
            }
        }

    def print_header(self):
        """Imprimir header del men√∫"""
        print("\n" + "="*60)
        print("üé§ COMPARADOR DE AUDIOS 3D-SPEAKER üé§")
        print("="*60)
        print(f"üíª Dispositivo: {self.device}")
        total_audios = len(self.get_audio_files())
        print(f"üéµ Archivos de audio encontrados: {total_audios}")
        print("="*60)

    def get_audio_files(self):
        """Obtener todos los archivos de audio disponibles en la carpeta data"""
        audio_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.ogg']
        audio_files = []
        
        # Buscar solo en el directorio data
        data_dir = 'data'
        
        if os.path.exists(data_dir):
            for root, dirs, files in os.walk(data_dir):
                for file in files:
                    if any(file.lower().endswith(ext) for ext in audio_extensions):
                        full_path = os.path.join(root, file)
                        # Filtrar archivos muy peque√±os o temporales
                        if os.path.getsize(full_path) > 1000:  # Al menos 1KB
                            audio_files.append(full_path)
        
        return sorted(audio_files)

    def select_model(self):
        """Seleccionar modelo a usar"""
        print("\nüìä SELECCIONA EL MODELO:")
        print("-" * 40)
        
        for key, model in self.models_config.items():
            print(f"{key}. {model['name']}")
            print(f"   {model['description']}")
            if 'model_paths' in model:
                # Verificar si el modelo est√° disponible
                model_available = any(os.path.exists(path) for path in model['model_paths'])
                status = "‚úÖ Disponible" if model_available else "‚ùå No encontrado"
                print(f"   {status}")
            
        print("\n4. üîÑ Comparar TODOS los audios (matriz de similitud)")
        print("0. Salir")
        
        while True:
            try:
                choice = input("\nSelecciona una opci√≥n (0-4): ").strip()
                
                if choice == "0":
                    print("üëã ¬°Hasta luego!")
                    sys.exit(0)
                elif choice == "4":
                    return "compare_all"
                elif choice in self.models_config:
                    return choice
                else:
                    print("‚ùå Opci√≥n inv√°lida. Intenta de nuevo.")
            except KeyboardInterrupt:
                print("\nüëã ¬°Hasta luego!")
                sys.exit(0)

    def get_audio_info(self, audio_file):
        """Obtener informaci√≥n detallada del archivo de audio"""
        try:
            wav, fs = torchaudio.load(audio_file)
            duration = wav.shape[-1] / fs
            channels = wav.shape[0] if len(wav.shape) > 1 else 1
            file_size = os.path.getsize(audio_file) / 1024  # KB
            
            return {
                'duration': duration,
                'sample_rate': fs,
                'channels': channels,
                'file_size': file_size,
                'samples': wav.shape[-1]
            }
        except Exception as e:
            return None

    def select_audio_file(self, prompt_text):
        """Seleccionar archivo de audio"""
        audio_files = self.get_audio_files()
        
        if not audio_files:
            print("‚ùå No se encontraron archivos de audio")
            return None
        
        print(f"\n{prompt_text}")
        print("-" * 50)
        
        # Agrupar por directorio para mejor visualizaci√≥n
        files_by_dir = {}
        for file in audio_files:
            dir_name = os.path.dirname(file)
            if dir_name not in files_by_dir:
                files_by_dir[dir_name] = []
            files_by_dir[dir_name].append(file)
        
        file_index = 1
        index_to_file = {}
        
        for dir_name, files in files_by_dir.items():
            print(f"\nüìÅ {dir_name}:")
            for file in files:
                filename = os.path.basename(file)
                
                # Obtener informaci√≥n del audio
                audio_info = self.get_audio_info(file)
                if audio_info:
                    info_str = f"({audio_info['duration']:.1f}s, {audio_info['sample_rate']}Hz, {audio_info['file_size']:.1f}KB)"
                else:
                    info_str = f"({os.path.getsize(file) / 1024:.1f} KB)"
                
                print(f"  {file_index:2d}. {filename} {info_str}")
                index_to_file[file_index] = file
                file_index += 1
        
        print("\n  0. Volver al men√∫ principal")
        print("  i. Mostrar informaci√≥n detallada de un archivo")
        
        while True:
            try:
                choice = input(f"\nSelecciona un archivo (1-{len(audio_files)}, i para info): ")
                
                if choice == "0":
                    return None
                elif choice.lower() == "i":
                    info_choice = input("N√∫mero del archivo para ver informaci√≥n: ")
                    try:
                        info_index = int(info_choice)
                        if info_index in index_to_file:
                            self.show_audio_info(index_to_file[info_index])
                        else:
                            print(f"‚ùå N√∫mero inv√°lido")
                    except ValueError:
                        print("‚ùå Por favor, ingresa un n√∫mero v√°lido")
                    continue
                
                index = int(choice)
                if index in index_to_file:
                    return index_to_file[index]
                else:
                    print(f"‚ùå Por favor, ingresa un n√∫mero entre 1 y {len(audio_files)}")
            except ValueError:
                print("‚ùå Por favor, ingresa un n√∫mero v√°lido")
            except KeyboardInterrupt:
                print("\nüëã Regresando al men√∫ principal...")
                return None

    def show_audio_info(self, audio_file):
        """Mostrar informaci√≥n detallada del archivo de audio"""
        print(f"\nüìÑ INFORMACI√ìN DEL ARCHIVO:")
        print("=" * 50)
        print(f"üìÅ Archivo: {os.path.basename(audio_file)}")
        print(f"üìÇ Ruta: {audio_file}")
        
        audio_info = self.get_audio_info(audio_file)
        if audio_info:
            print(f"‚è±Ô∏è  Duraci√≥n: {audio_info['duration']:.2f} segundos")
            print(f"üîä Frecuencia: {audio_info['sample_rate']} Hz")
            print(f"üìª Canales: {audio_info['channels']}")
            print(f"üìä Muestras: {audio_info['samples']:,}")
            print(f"üíæ Tama√±o: {audio_info['file_size']:.1f} KB")
            
            # Verificar si es adecuado para el modelo
            if audio_info['sample_rate'] != 16000:
                print(f"‚ö†Ô∏è  Nota: El archivo ser√° resampleado de {audio_info['sample_rate']}Hz a 16000Hz")
            
            if audio_info['duration'] < 1.0:
                print(f"‚ö†Ô∏è  Advertencia: Archivo muy corto ({audio_info['duration']:.2f}s). Puede afectar la precisi√≥n.")
            elif audio_info['duration'] > 30.0:
                print(f"‚ÑπÔ∏è  Informaci√≥n: Archivo largo ({audio_info['duration']:.2f}s). Solo se usar√° una porci√≥n.")
        else:
            print("‚ùå No se pudo leer la informaci√≥n del archivo")
        
        print("=" * 50)
        input("Presiona Enter para continuar...")

    def load_audio(self, wav_file, target_fs=16000):
        """Cargar y procesar archivo de audio"""
        wav, fs = torchaudio.load(wav_file)
        
        if fs != target_fs:
            print(f'[INFO]: Resampling {os.path.basename(wav_file)} from {fs} to {target_fs} Hz')
            wav = torchaudio.functional.resample(wav, fs, target_fs)
        
        if wav.shape[0] > 1:
            wav = wav[0, :].unsqueeze(0)
        
        return wav

    def extract_embedding(self, wav_file, model):
        """Extraer embedding de un archivo de audio"""
        wav = self.load_audio(wav_file)
        feat = self.feature_extractor(wav).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            embedding = model(feat).detach().squeeze(0).cpu().numpy()
        
        return embedding

    def cosine_similarity(self, emb1, emb2):
        """Calcular similitud coseno entre dos embeddings"""
        emb1_norm = emb1 / np.linalg.norm(emb1)
        emb2_norm = emb2 / np.linalg.norm(emb2)
        similarity = np.dot(emb1_norm, emb2_norm)
        return similarity

    def compare_with_original_script(self, model_choice, audio1, audio2):
        """Usar el script original infer_sv.py"""
        model_config = self.models_config[model_choice]
        script_path = Path("speakerlab") / "bin" / "infer_sv.py"
        
        cmd = [
            sys.executable,
            str(script_path),
            "--model_id", model_config["model_id"],
            "--wavs", audio1, audio2
        ]
        
        print(f"üîÑ Ejecutando script original...")
        print(f"üìä Modelo: {model_config['name']}")
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path(__file__).parent)
            
            # Buscar el score en la salida
            lines = result.stdout.split('\n')
            score = None
            
            for line in lines:
                if "The similarity score" in line:
                    match = re.search(r'(\d+\.\d+)', line)
                    if match:
                        score = float(match.group(1))
                        break
            
            if score is not None:
                print(f"\nüìä RESULTADOS:")
                print(f"üéØ Similitud coseno: {score:.4f}")
                
                # Interpretaci√≥n usando thresholds del modelo
                thresholds = model_config.get("thresholds", [0.70, 0.60, 0.45, 0.30])
                self.interpret_results(score, thresholds, True)
                
                return score
            else:
                print("‚ùå No se pudo extraer el score de similitud")
                if result.stderr:
                    print(f"Error: {result.stderr}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error ejecutando script original: {e}")
            return None

    def compare_with_model(self, model_choice, audio1, audio2):
        """Comparar usando modelo cargado directamente"""
        model_config = self.models_config[model_choice]
        
        print(f"ü§ñ Cargando modelo {model_config['name']}...")
        
        try:
            # Crear modelo
            model_class = dynamic_import(model_config['config']['obj'])
            model = model_class(**model_config['config']['args'])
            
            # Intentar cargar pesos preentrenados
            use_pretrained = False
            for model_path in model_config['model_paths']:
                if os.path.exists(model_path):
                    try:
                        print(f"üì¶ Cargando pesos desde {os.path.basename(model_path)}...")
                        checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
                        
                        if isinstance(checkpoint, dict):
                            if 'model' in checkpoint:
                                model.load_state_dict(checkpoint['model'], strict=False)
                            elif 'state_dict' in checkpoint:
                                model.load_state_dict(checkpoint['state_dict'], strict=False)
                            else:
                                model.load_state_dict(checkpoint, strict=False)
                        else:
                            model.load_state_dict(checkpoint, strict=False)
                        
                        use_pretrained = True
                        print("‚úÖ Modelo preentrenado cargado exitosamente")
                        break
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Error cargando {model_path}: {e}")
                        continue
            
            if not use_pretrained:
                print("‚ö†Ô∏è  Usando modelo sin entrenar (resultados no confiables)")
            
            model.to(self.device)
            model.eval()
            
            # Extraer embeddings
            print("üîÑ Procesando audios...")
            embedding1 = self.extract_embedding(audio1, model)
            embedding2 = self.extract_embedding(audio2, model)
            
            # Calcular similitud
            similarity = self.cosine_similarity(embedding1, embedding2)
            
            print(f"\nüìä RESULTADOS:")
            print(f"üéØ Similitud coseno: {similarity:.4f}")
            print(f"üìä Embedding: {embedding1.shape[0]} dimensiones")
            
            # Interpretaci√≥n
            thresholds = model_config.get("thresholds", [0.70, 0.60, 0.45, 0.30])
            self.interpret_results(similarity, thresholds, use_pretrained)
            
            return similarity
            
        except Exception as e:
            print(f"‚ùå Error con modelo {model_config['name']}: {e}")
            return None

    def interpret_results(self, similarity, thresholds, use_pretrained):
        """Interpretar resultados seg√∫n thresholds"""
        if use_pretrained:
            if similarity > thresholds[0]:
                status = "üü¢ MISMO LOCUTOR"
                confidence = "MUY ALTA CONFIANZA"
            elif similarity > thresholds[1]:
                status = "üü¢ PROBABLEMENTE MISMO LOCUTOR"
                confidence = "ALTA CONFIANZA"
            elif similarity > thresholds[2]:
                status = "üü° POSIBLEMENTE MISMO LOCUTOR"  
                confidence = "MEDIA CONFIANZA"
            elif similarity > thresholds[3]:
                status = "üü† PROBABLEMENTE DIFERENTES"
                confidence = "BAJA SIMILITUD"
            else:
                status = "üî¥ LOCUTORES DIFERENTES"
                confidence = "MUY BAJA SIMILITUD"
        else:
            status = "‚ö†Ô∏è  RESULTADO NO CONFIABLE"
            confidence = "MODELO SIN ENTRENAR"
        
        print(f"üéØ Resultado: {status}")
        print(f"üìà Confianza: {confidence}")

    def compare_all_audios(self, model_choice):
        """Comparar todos los audios disponibles y crear matriz de similitud"""
        audio_files = self.get_audio_files()
        
        if len(audio_files) < 2:
            print("‚ùå Se necesitan al menos 2 archivos de audio")
            return
        
        if len(audio_files) > 10:
            print(f"‚ö†Ô∏è  Se encontraron {len(audio_files)} archivos. Esto puede tomar mucho tiempo.")
            confirm = input("¬øContinuar? (s/n): ").lower()
            if confirm not in ['s', 'si', 's√≠', 'y', 'yes']:
                return
        
        model_config = self.models_config[model_choice]
        print(f"\nüîÑ Comparando {len(audio_files)} archivos con {model_config['name']}...")
        
        # Cargar modelo
        try:
            model_class = dynamic_import(model_config['config']['obj'])
            model = model_class(**model_config['config']['args'])
            
            # Cargar pesos preentrenados
            use_pretrained = False
            for model_path in model_config['model_paths']:
                if os.path.exists(model_path):
                    try:
                        checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
                        if isinstance(checkpoint, dict):
                            if 'model' in checkpoint:
                                model.load_state_dict(checkpoint['model'], strict=False)
                            elif 'state_dict' in checkpoint:
                                model.load_state_dict(checkpoint['state_dict'], strict=False)
                            else:
                                model.load_state_dict(checkpoint, strict=False)
                        else:
                            model.load_state_dict(checkpoint, strict=False)
                        use_pretrained = True
                        break
                    except Exception as e:
                        continue
            
            model.to(self.device)
            model.eval()
            
            # Extraer embeddings de todos los archivos
            print("üîÑ Extrayendo embeddings...")
            embeddings = {}
            file_names = []
            
            for i, audio_file in enumerate(audio_files):
                try:
                    print(f"   üìÑ Procesando {i+1}/{len(audio_files)}: {os.path.basename(audio_file)}")
                    embedding = self.extract_embedding(audio_file, model)
                    embeddings[audio_file] = embedding
                    file_names.append(os.path.basename(audio_file))
                except Exception as e:
                    print(f"   ‚ùå Error con {audio_file}: {e}")
                    continue
            
            if len(embeddings) < 2:
                print("‚ùå No se pudieron procesar suficientes archivos")
                return
            
            # Crear matriz de similitud
            print("\nüìä Calculando matriz de similitud...")
            similarity_matrix = np.zeros((len(embeddings), len(embeddings)))
            audio_list = list(embeddings.keys())
            
            for i, audio1 in enumerate(audio_list):
                for j, audio2 in enumerate(audio_list):
                    if i == j:
                        similarity_matrix[i, j] = 1.0
                    elif i < j:  # Solo calcular la mitad superior
                        similarity = self.cosine_similarity(embeddings[audio1], embeddings[audio2])
                        similarity_matrix[i, j] = similarity
                        similarity_matrix[j, i] = similarity  # Simetr√≠a
            
            # Mostrar resultados
            print("\n" + "="*80)
            print("üìä MATRIZ DE SIMILITUD")
            print("="*80)
            
            # Header con nombres de archivos
            header = "Archivo".ljust(20)
            for name in file_names:
                header += f"{name[:10]:<12}"
            print(header)
            print("-" * len(header))
            
            # Filas de la matriz
            for i, name in enumerate(file_names):
                row = f"{name[:18]:<20}"
                for j in range(len(file_names)):
                    score = similarity_matrix[i, j]
                    if i == j:
                        row += f"{'1.0000':<12}"
                    else:
                        row += f"{score:.4f}{'':6}"
                print(row)
            
            # An√°lisis de grupos
            print("\nüìà AN√ÅLISIS DE GRUPOS:")
            print("-" * 40)
            
            threshold = model_config.get("thresholds", [0.70, 0.60, 0.45, 0.30])[1]  # Usar segundo threshold
            high_similarity_pairs = []
            
            for i in range(len(audio_list)):
                for j in range(i+1, len(audio_list)):
                    if similarity_matrix[i, j] > threshold:
                        pair = (file_names[i], file_names[j], similarity_matrix[i, j])
                        high_similarity_pairs.append(pair)
            
            if high_similarity_pairs:
                print(f"üü¢ Pares con alta similitud (> {threshold:.2f}):")
                for name1, name2, score in sorted(high_similarity_pairs, key=lambda x: x[2], reverse=True):
                    print(f"   {name1} ‚Üî {name2}: {score:.4f}")
            else:
                print(f"üî¥ No se encontraron pares con alta similitud (> {threshold:.2f})")
            
            # Guardar resultados
            save_results = input("\nüíæ ¬øGuardar resultados en archivo? (s/n): ").lower()
            if save_results in ['s', 'si', 's√≠', 'y', 'yes']:
                import csv
                import datetime
                
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"similarity_matrix_{model_choice}_{timestamp}.csv"
                
                with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
                    writer = csv.writer(csvfile)
                    
                    # Header
                    header_row = ['Archivo'] + file_names
                    writer.writerow(header_row)
                    
                    # Datos
                    for i, name in enumerate(file_names):
                        row = [name] + [f"{similarity_matrix[i, j]:.4f}" for j in range(len(file_names))]
                        writer.writerow(row)
                
                print(f"‚úÖ Resultados guardados en: {filename}")
            
        except Exception as e:
            print(f"‚ùå Error en comparaci√≥n masiva: {e}")
            import traceback
            traceback.print_exc()

    def run(self):
        """Ejecutar el men√∫ principal"""
        while True:
            self.print_header()
            
            # Seleccionar modelo o acci√≥n
            choice = self.select_model()
            
            if choice == "compare_all":
                # Seleccionar modelo para comparaci√≥n masiva
                print("\nüìä SELECCIONA EL MODELO PARA COMPARACI√ìN MASIVA:")
                print("-" * 50)
                
                available_models = {}
                for key, model in self.models_config.items():
                    if not model.get('use_original'):  # Excluir script original para comparaci√≥n masiva
                        model_available = any(os.path.exists(path) for path in model['model_paths'])
                        if model_available:
                            available_models[key] = model
                            print(f"{key}. {model['name']} ‚úÖ")
                        else:
                            print(f"{key}. {model['name']} ‚ùå (No disponible)")
                
                if not available_models:
                    print("‚ùå No hay modelos disponibles para comparaci√≥n masiva")
                    input("Presiona Enter para continuar...")
                    continue
                
                model_choice = input(f"\nSelecciona modelo (1-{len(self.models_config)-1}): ").strip()
                
                if model_choice in available_models:
                    self.compare_all_audios(model_choice)
                else:
                    print("‚ùå Selecci√≥n inv√°lida")
                
                input("\nPresiona Enter para continuar...")
                continue
            
            # Flujo normal para comparaci√≥n de dos audios
            model_choice = choice
            
            # Seleccionar primer audio
            audio1 = self.select_audio_file("üéµ SELECCIONA EL PRIMER ARCHIVO DE AUDIO:")
            if not audio1:
                continue
            
            # Seleccionar segundo audio
            audio2 = self.select_audio_file("üéµ SELECCIONA EL SEGUNDO ARCHIVO DE AUDIO:")
            if not audio2:
                continue
            
            # Mostrar selecci√≥n
            print("\n" + "="*60)
            print("üìã CONFIGURACI√ìN SELECCIONADA:")
            print("="*60)
            print(f"ü§ñ Modelo: {self.models_config[model_choice]['name']}")
            print(f"üéµ Audio 1: {os.path.basename(audio1)}")
            print(f"üéµ Audio 2: {os.path.basename(audio2)}")
            print(f"üñ•Ô∏è  Dispositivo: {self.device}")
            print("="*60)
            
            # Confirmar ejecuci√≥n
            confirm = input("\n¬øContinuar con la comparaci√≥n? (s/n): ").lower()
            if confirm not in ['s', 'si', 's√≠', 'y', 'yes']:
                continue
            
            # Ejecutar comparaci√≥n
            if self.models_config[model_choice].get('use_original'):
                score = self.compare_with_original_script(model_choice, audio1, audio2)
            else:
                score = self.compare_with_model(model_choice, audio1, audio2)
            
            if score is not None:
                print(f"\n‚úÖ Comparaci√≥n completada exitosamente")
            else:
                print(f"\n‚ùå Error en la comparaci√≥n")
            
            # Preguntar si quiere hacer otra comparaci√≥n
            print("\n" + "-"*60)
            another = input("¬øRealizar otra comparaci√≥n? (s/n): ").lower()
            if another not in ['s', 'si', 's√≠', 'y', 'yes']:
                print("üëã ¬°Hasta luego!")
                break

def main():
    try:
        comparator = AudioComparator()
        comparator.run()
    except KeyboardInterrupt:
        print("\n\nüëã ¬°Hasta luego!")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
